			+--------------------+
			|    CS 421/521      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Rohan Shah  <rmshah2@buffalo.edu>
Venkata Ramesh Thetakali <vthetaka@buffalo.edu>
Liang Jia Jiang <liangjia@buffalo.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

*** In the thread.h,

we add a ticks_count integer variable which keeps count of the amount of time the thread has to sleep. 

*** In the timer.c we added the 

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

*** We disable our interrupt handle to to block the thread in the thread_block(). And it calls the timer_interrupt() after every tick. 



>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

*** 
The function in interrupt handler will check every thread and wake them up. 

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

*** Interrupts are turned off after checking with the conditional statements and checks through the interrupt handler which corroborates synchronization.  

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

** when the timer is interrupted it checks for the ticks elapsed and based on it wakes/sleeps the threads. 

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

*** This is the simplest way to avoid busy waiting and the runtime is very fast and implementation is straight forward. 
			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

list Highest_Pri_List 	we will be creating a list that contains the highest priority
threads to run them using round robin scheduling.

list Waiting_List 		we will also creating a waiting list for threads that are waiting
on locks or other threads

int Highest_Pri 	We will use this variable to keep track of the highest priority
when this number changes, we will clean out the Highest_Pri_List



>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)


High Priorty		Medium Priorty		Low Priorty
T1 -> (62)			T3 -> (32)		   	T4 -> (10)
T2 -> (61)

let say T1 is now locked because it is waiting for T3,
T1 would donate it's priorty to T3 so that it become a high priorty

High Priorty		Medium Priorty		Low Priorty
T1 -> (62)							   	T4 -> (10)
T2 -> (61)
T3 -> (62)

after T3 unlocks so that T1 can run again it returns it's proioty and 
moves back down to a Medium Priorty thread

High Priorty		Medium Priorty		Low Priorty
T1 -> (62)			T3 -> (32)		   	T4 -> (10)
T2 -> (61)

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?
Everytimes a priority changes or a new thread is implemented we will be 
calling a method that check for the highest priority this way only the 
thread with the highest priority will be running.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?
When a lock_acquire occurs we will compare priority with the lock thread
if it's low we will replace the priority with the high priority thread
therefore the low priority will finish first.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.
When the lock_release occurs the thread will then recover it's own thread priority
and since we just made a copy of the high priority thread if it's still the
highest priority thread, it will contiune running.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?
Yes, we will use a lock to prevent race situtation by testing if 
two thread have the same priority, while scanning the thread priority, if the thread
priority matches another one on the list we will put a lock on the thread until
the other thread on the list, releases by lowering it's priority or finishing.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?
We choose this design over another design we considered because it seems like
a simple design, in our minds we feel like this method will synchronizate all of 
our problem 


			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Follwing variables added to struct thread in thread.h

struct thread

	int thread_nice;    //the thread's nice value

	int thread_recent_cpu; //the most recent CPU time taken by the thread

Added Nice value limits to a thread

#define MIN_NICE -20   //Minimum nice value for a thread
#define DEFAULT_NICE 0 //Default nice value for a thread
#define MAX_NICE 20    //Maximum nice value for a thread

variable avg_load added in thread.c to calculate threads run in the past minute

static int avg_load     //average number of threads run in the CPU in the past 1 minute


---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

For each thread,

priority = PRI_MAX - (recent_cpu/4) - nice*2;

recent_cpu = 2*avg_load/(2*avg_load+1)*recent_cpu+nice;

avg_load = 59/60*avg_load + 1/60*threads_in_ready_queue;
  
timer               recent_cpu                     priority              thread to run             ready queue            REMARKS
ticks         A        B        C             A       B       C  
-----        ---      ---      ---           ---     ---     ---         ---------------         ---------------        ----------------
 0            0        0        0             63      61      59               A                      B C
 4            4	       0        0	      62      61      59               A                      B C
 8            8        0        0             61      61      59               B                      A C               Round Robin scheduling since A and B have same priority
12            8        4        0             61      60      59               A                      B C
16            12       4        0             60      60      59               B                      A C               Round Robin scheduling since A and B have same priority
20            12       8        0             60      59      59               A                      C B              
24            16       8        0             59      59      59               C                      B A               Round Robin scheduling since all have same priority
28            16       8        4             59      59      58               B                      A C               Round Robin scheduling since A and C have same priority
32            16       12       4             59      58      58               A                      C B               Round Robin scheduling since B and C have same priority
36            20       12       4             58      58      58               C                      B A               Round Robin scheduling since all have same priority

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

yes, when there are multiple threads with same priority to run, ambiguity occurs on 
which thread to run. I resolved this ambiguity following Round Robin scheduling where a 
thread which is in the ready queue and has the same priority with one or more threads 
in the ready queue, then the thread which has run least recently will be scheduled, 
however i didn't pre-empt the thread when it has completed execution before it has 
reached it's time slice and allowed the thread to continue running till the time slice has expired.

This design is in line with the priority scheduler implemented.  

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

For all the threads, only nice value is computed outside the interrupt handler since
changing nice value of a thread affects its priority. The entire cost of scheduling occurs
inside the interrupt handler where at each timer_ticks all the threads priority have 
to be updated (but in practicality only priority of thread which has run recently needs to be updated)
where as for every second, recent_cpu, load_avg and priority needs to be calculated for every thread
as mentioned above since recent_cpu changes every second. This involves a lot of overhead on scheduler
when there are huge number of threads. Hence this type of priority scheduling affects performance
when there are large number of processes/threads needs to be run by the scheduler. 

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

Advantages>>
The design is very simple and easy to understand.
Minimal changes with extra variables and functions
Implemented fixed point math which can be reused, however implemented only necessary functions 

Disadvantages>>
The design doesn't take care of deadlock detection and prevention, since there can be a deadlock
when multiple threads are competiting to enter critical region, it is very necessary to avoid deadlocks
for optimal resource use and efficient execution.

By implementing fixed point math, there can be be a case of overflows in floating point numbers and
this should be taken care either by kernel or handled by user implementing pintos, however this seems
not so important at this stage and this has been skipped for now.

If i have extra time to work on, I would have tried to design advanced scheduling in such a way that the
code handles deadlock detection and prevention. This can be handled by implementing algorithms for detecting 
deadlocks like resource allocation graphs or Banker algorithm.

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not? 

Since pintos kernel doesn't support fixed point arithmetic, i implemented
fixed point math to calculate recent_cpu and load_avg in a header file, since
these values can be in float. I have used the standard function definitions defined in
pintos documentation. In this way i abstracted the fixed point math in a header file, 
so that these can be reused elsewhere when required. This approach separates abstraction
from implementation.     

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
